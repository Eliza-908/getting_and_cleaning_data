res
?separate
separage(res,sex_class, into = c("sex", "class"))
separate(res,sex_class, into = c("sex", "class"))
submit()
students3
submit()
?spread
submit()
submit()
submit()
reset()
submit()
submit()
submit()
reset()
submit()
submit()
submit()
extract_numeric("class5")
submit()
?extract_numeric
submit()
submit()
?mutate
submit()
submit()
submit()
students4
submit()
submit()
submit()
passed
failed
passed <- mutate(status = "passed")
passed <- mutate(passed, status = "passed")
failed <- mutate(failed, status = "failed")
bind_rows(passed, failed)
sat
?separate
submit()
submit()
?select
submit()
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = "lubridate")
help(package = lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
second(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 5, minute = 22)
this_moment <- update(this_moment, hours = 5, minutes = 22)
this_moment
nyc <- now("America/New_York")
nyc
nyc + days(2)
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- withtz(arrive, tzone = "Asia/Hong_Kong")
arrive <- with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
mdy("June 17, 2008", tz = "Singapore")
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?new_interval
how_long <- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
install_from_swirl("Exploratory Data Analysis")
swirl()
swirl()
install_from_swirl("Statistical Inference")
swirl()
33/36
deck
52
4/52
0
12/52
2/51
.64
64/100
mypdf
integrage(mypdf, 0, 1.6)
integrate(mypdf, 0, 1.6)
.5
.25
4
sqrt(2)
.997*.001
(1-.985)*(1-.001)
0.000997/(0.000997+0.014985)
3.5
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_low)
.5*(edh + edl)
integrage(myfunc, 0, 2)
integrate(myfunc, 0, 2)
spop
mean(spop)
allsam
apply(allsam, 1, mean)
mean(smeans)
dice_sqr
ex2_fair <- dice_sqr*dice_fair
ex2_fair <- sum(dice_sqr*dice_fair)
ex2_fair -3.5^2
sum(dice_sqr*dice_high) - edh^2
sd(apply(matrix(rnorm(10000),1000),1,mean))
1/sqrt(10)
1/sqrt(120)
sd(apply(matrix(runif(10000),1000),1,mean))
2/sqrt(10)
sd(apply(matrix(rpois(10000,4),1000),1,mean))
1/(2*sqrt(10))
sd(apply(matrix(sample(0:1,10000,TRUE),1000),1,mean))
pnorm(93, 100, 10)
.05*.93/(.05*.93+(1-.05)*(1-.88))
.05*.93/(.05*.93+(1-.05)*.88)
qnorm(.95,100,2)
choose(6,5)*.5^6 + choose(6,6)*5^6
pbinom(4,size = 6, prob = 0.5, lower.tail = FALSE)
pnorm(.51, .5, (1/12)^2/100)
1+4+9+16+25+36
/6
91/6
91/6 - 3.5^2
ppois(20,lambda = 16.5*2)
ppois(20,lambda = 16.5*2)*100
ppois(10,lambda = 15)
1/12
pnorm(70,80,10)
qnorm(.95,1100,75)
qnorm(.95,1100,75^2/100)
qnorm(.95,1100,75/sqrt(100))
.5^5*(choose(5,4)+choose(5,5))
pnorm(16,15,10/sqrt(100)) - pnorm(14, 15, 10/sqrt(100))
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
library(ggplot2)
str(mpg)
qplot(displ, hwy, data = mpg)
qplot(displ, hwy, data = mpg, color = drv)
qplot(displ, hwy, data = mpg, geom = c("points", "smooth"))
qplot(displ, hwy, data = mpg, geom = c("point", "smooth"))
qplot(hwy, data = mpg, fill = drv)
qplot(displ, hwy, data=mpg, facets = .~drv)
qplot(hwy, data=mpg, facets = .~drv, binwidth = 2)
qplot(hwy, data=mpg, facets = drv.~, binwidth = 2)
qplot(hwy, data=mpg, facets = drv~., binwidth = 2)
qplot(displ, hwy, data = mpg)
clear
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(datasets)
data("airquality")
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
data(sleep)
head(sleep)
library(datasets)
data("ChickWeight")
library(reshape2)
wideCW <- dcast(ChickWeight, Diet + Chick ~ Time, value.var = 'weight')
library(dplyr)
wideCW
pt(2.5,15,lower.tail = FALSE)
whatever
:()
.5^8*(choose(8,7) + choose(8,8))
pbinom(6, size = 8, prob = 0.5, lower.tail = FALSE)
pbinom(6, size = 8, prob = 0.5, lower.tail = FALSE)*2
ppois(9, 5, lower.tail = FALSE)
data("mtcars")
t.test(mpg)
t.test(mtcars$mpg)
round(t.test(mtcars$mpg)$conf.int)
round(qt(.975, df = 8)*1/3,2)
round(t.test(mtcars$mpg, var.equal = TRUE)$conf.int)
head(mtcars)
round(t.test(mtcars$mpg, cyl, var.equal = TRUE)$conf.int)
round(t.test(mtcars$mpg, mtcars$cyl, var.equal = TRUE)$conf.int)
m4 <- mtcars$mpg[mtcars$cyl == 4]
m6 <- mtcars$mpg[mtcars$cyl == 6]
confint <- as.vector(t.test(m4,m6,var.equal = TRUE)$conf.int)
confint
(1.8^2*1.5^2)
.5*(1.8^2+1.5^2)
.5*(1.8^2+1.5^2)/3
8*(1.5^2+1.8^2)/16
round(t.test(9,1100,30)$conf.int)
?t.test
mean <- 1100
sd <- 30
n <- 9
p <- .95
ci <- mbv + c(-1,1)*qt(p+(1-p)/2,n-1)*s/sqrt(n)
ci <- mean + c(-1,1)*qt(p+(1-p)/2,n-1)*s/sqrt(n)
ci <- mean + c(-1,1)*qt(p+(1-p)/2,n-1)*sd/sqrt(n)
ci
upper <- 0
diff <- -2
sd <- (upper - diff)*sqrt(n)/qt(p+(1-p)/2, n-1)
sd
as.vector(t.test(3,5,.6,.68))
ny <- 10
nx <- 10
vary <- .6
varx <- .68
uy <- 3
ux <- 5
op <- sqrt(((nx -1)*varx*(ny-1)*vary)/(nx+ny-2)
op <- sqrt(((nx -1)*varx*(ny-1)*vary)/(nx+ny-2))
op <- sqrt(((nx -1)*varx*(ny-1)*vary)/(nx+ny-2))
ci <- uy - ux + c(-1,1)*qt(.975, df=ny+nx-2)*op*(1/ny+1/nx)^0.5
round(ci,2)
quantile = 0.95
ny <- 9
nx <- 9
oy <- 1.5
ox <- 1.8
uy <- -3
ux <- 1
step1 <- (nx-1)*(ox^2 + oy^2)
step2 <- nx + ny -2
op <- sqrt(step1/step2)
ci <- uy - ux + c(-1,1)*qt(quantile, df=ny+nx-2)*op*sqrt(1/ny+1/nx))
ci <- uy - ux + c(-1,1)*qt(quantile, df=ny+nx-2)*op*sqrt(1/ny+1/nx)
ci
?set.seed
?data.frame
z.test(mtcars$mpg)
getwd()
ls
this <- read.csv("Indiachworkers.csv")
str(this)
this <- read.csv("Indiachworkers.csv", header = TRUE)
str(this)
names(this)
library(ggplot2)
ggplot(this$Name.of.the.State.UT, this$X2011)
his(this$X2011)
hist(this$X2011)
plot(this$Name.of.the.State.UT, this$X2011)
head(this)
that <- read.csv("Indiachworkers.csv", header = TRUE, transpose = TRUE)
that <- read.csv("Indiachworkers.csv", header = TRUE, transpose = T)
that <- t(this)
that
str(that)
summary(that)
install.packages("node.js")
npm -g install marked
power.t.test(n = 16, delta = 2, sd = 4, type = "one.sample",alt = 'one.sided')$power
power.t.test(power = 0.8, delta = 2, sd = 4, type = "one.sample", alt = "one.sided")$n
data("mtcars")
mean(mtcars$mpg)
mpgmean <- mean(mtcars$mpg)
s <- sd(mtcars$mpg)
z <- qnorm(0.05)
mu0 <- mn - z*s/sqrt(nrow(mtcars))
mu0 <- mpgmean - z*s/sqrt(nrow(mtcars))
mu0
m4 <- mtcars[mtcars$cyl == 4]
m4 <- subset(mtcars, mtcars$cyl == 4)
head(m4)
m6 <- subset(mtcars, mtcars$cyl == 6)
mean(m4)
t.test(m4$mpg,m6$mpg, var.equal = FALSE, paired = FALSE, alternative = "two.sided")
?pbinom
ans <- round(pbinom(54, p = 0.5, size = 100, lower.tail = FALSE),4)
ans
pv = ppois(15800 - 1, lambda = 520*30, lower.tail = FALSE)
pv
m1 <- 10; m2 <- 11
n1 <- n2 <- 100
s<- 4
se <- s*sqrt(1/n1 + 1/n2)
ts <- (m2-m1)/se
pv <- 2*pnorm(-abs(ts))
pv
power.t.test(n = 100, sd = 4, mean = 10)$power
pnorm(10 + qnorm(.95)*.4, mean = 11, sd = .4, lower.tail = FALSE)
(qnorm(.95)+qnorm(.8))^2 *.04^2 / .01^2
subject <- c(1:5)
baseline <- c(140,138,150,148,135)
week2 <- c(132,135,151,146,130)
examinations <- data.frame(subject,baseline,week2)
examinations
test <- t.test(x = examinations$baseline, y = examinations$week2, alt = "two.sided", paired = TRUE)
pval <- test$p.value
pval
n <- 9
u <- 1100
s <- 30
quantile<- 0.975
ci <- u + c(-1,1) * qt(quantile, df = n-1) * s /sqrt(n)
ci
n <- 4
x <- 3
test <- binom.test(x=x,n=n, alt = "greater")
round(test$p.value,2)
rate <- .01
errors <- 10
days <- 1787
test <- poisson.test(errors,T=days,r=rate,alt="less")
round(test$p.value,2)
n <- 100
u <- 0.01
s <- .04
p <- 0.05
pow <- power.t.test(n=n,delta = u,sd=s,sig.level = p,type="one.sample", alt = one.sided)$power
pow <- power.t.test(n=n,delta = u,sd=s,sig.level = p,type="one.sample", alt = "one.sided")$power
round(pow,2)
u <- 0.01
pow <- 0.9
n <- power.t.test(power = pow, mean=u, sd=s,type="one.sample",alt="one.sided")$n
n <- power.t.test(power = pow, delta =u, sd=s,type="one.sample",alt="one.sided")$n
ceiling(n/10)*10
n
?t.tet
t.test
?t.test
library(reshape2)
data(mtcars)
mtcars$carnames <- rownames(mtcars)
carMelt <- melt(mtcars, id=c("carname","gear","cyl"),measure.vars=c("mgp,"hp))
carMelt <- melt(mtcars, id=c("carname","gear","cyl"),measure.vars=c("mgp","hp"))
carMelt <- melt(mtcars, id=c("carnames","gear","cyl"),measure.vars=c("mgp","hp"))
carMelt <- melt(mtcars, id=c("carnames","gear","cyl"),measure.vars=c("mpg","hp"))
head(carMelt,n=3)
tail(carMelt,n=3)
cylData <- dcast(carMelt,cyl~variable)
cylData <- dcast(carMelt, cyl ~ variable)
?dcast
cylData <- dcast(carMelt, cyl ~ variable, mean)
cylData
head(InsectSprays)
tapply(InsectSprays$count,InsectSprays$spray,sum)
spIns <- split(InsectSprays$count,InsectSprays$spray)
spIns
sprCount <- lapply(spIns,sum)
sprCount
unlist(sprCount)
saaply(spIns,sum)
sapply(spIns,sum)
ddply(InsectSprays,.(spray),summarize,sum=sum(count))
library(dplyr)
ddply(InsectSprays,.(spray),summarize,sum=sum(count))
library(plyr)
ddply(InsectSprays,.(spray),summarize,sum=sum(count))
spraySums <- ddply(InsectSprays,.(spray),summarize,sum=ave(count,FUN=sum))
head(spray(sum))
head(spraySums)
getwd(0)
getwd()
source('~/datasciencecoursera/run_analysis.R')
files
source('~/datasciencecoursera/run_analysis.R')
head(files)
library(httr)
direction <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileURL, destfile = "acs.csv", method = "curl")
download.file(fileUrl, destfile = "acs.csv", method = "curl")
dateDownloaded <- date()
acs <- read.table("./acs.csv",spe=",",header=TRUE)
acs <- read.table("./acs.csv",sep=",",header=TRUE)
head(acs)
acgricultureLogical <- (acs$ACR==3 &acs$AGS==6)
agricultureLogical <- (acs$ACR==3 &acs$AGS==6)
which(agricultureLogical)
class(agricultureLogical)
library(jpeg)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(fileUrl,destfile = "jeff.jpg",method="curl")
img.n<- readJPEG("jeff.jpg",TRUE)
quantile(img.n,probs = c(0.3,0.8))
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl,destfile = "gdp.csv",method="curl")
gdp <- read.csv("./gdp.csv")
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl1,destfile = "edu.csv",method="curl")
edu <- read.csv("./edu.csv")
names(gdp)
X = CountryCode
gdpclean<- gdp[5:194,]
mergeddata<- as.data.frame(merge(gdpclean,edu,by.x="X",by.y="CountryCode"))
mergeddata$Gross.domestic.product.2012 <- as.numeric(as.character(mergeddata$Gross.domestic.product.2012))
summary(mergeddata[mergeddata$Income.Group=="High income:OECD",])
quantile(mergedData$Gross.domestic.product.2012,probs=c(0.2,0.4,0.6,0.8,1))
quantile(mergeddata$Gross.domestic.product.2012,probs=c(0.2,0.4,0.6,0.8,1))
library(Hmisc)
mergeddata$gdp=cut2(mergedData$Gross.domestic.product.2012,g=5)
?cut2
??cut2
install.packages("Hmisc")
library(Hmisc)
mergedData$gdp=cut2(mergedData$Gross.domestic.product.2012,g=5)
mergeddata$gdp=cut2(mergeddata$Gross.domestic.product.2012,g=5)
table(mergeddata$Income.Group,mergeddata$gdp)
mean(mergeddata[mergeddata$Income.Group=="High income: OECD",])
summary(mergeddata[mergeddata$Income.Group=="High income: OECD",])
summary(mergeddata[mergeddata$Income.Group=="High income: nonOECD",])
names(gdp)
summary(mergeddata)
library(data.table)
GDP <- data.table(read.csv("gdp.csv", skip = 4, nrows = 191))
GDP <- GDP[X != ""]
GDP <- GDP[,list(X,X.1,X.3,X.4)]
setnames(GDP,c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP", "Long.Name", "GDP"))
data2 <- merge(gdp,edu,all = TRUE, by = c("CountryCode"))
data2 <- merge(GDP, edu, all = TRUE, by = c("CountryCode"))
sum(!is.na(unique(data2$rankingGDP)))
data2[order(rankingGDP,decreasing = TRUE), list(CountryCode, Long.Name.x,Long.Name.y,rankingGDP,GDP)][13]
source('~/datasciencecoursera/run_analysis.R')
colnames(final_data)
str(final_data)
source('~/datasciencecoursera/run_analysis.R')
head(data_names)
data_names <- names(final_data)
data_names <- gsub("Mag","Magnitude",data_names)
data_names
data_names <- names(final_data)
# Tidy up the data names
data_names <- gsub("Mag","Magnitude",data_names)
data_names <- gsub("-mean","Mean",data_names)
data_names <- gsub("-std","StDev",data_names)
data_names <- gsub("Acc","Accelerometer",data_names)
data_names <- gsub("Gyro","Gyroscope",data_names)
data_names
data_names <- gsub("()","",data_names)
data_names
data_names <- gsub("()","",data_names)
data_names
names(final_data) <- data_names
head(final_data)
mean_std_features
str(final_data)
mean_std_features <- grep("-(mean|std|subject|activity)\\(\\)", features[,2])
mean_std_features
final_data <- final_data[, mean_std_features]
final_data <- rbind(training_data,test_data)
names(final_data)
mean_std_features <- grep("-(activity_id|subject_id|mean|std)\\(\\)", features[,2])
# Subset the dataset by the desired columns
final_data <- final_data[, mean_std_features]
names(final_data) <- features[mean_std_features, 2]
head(final_data)
str(final_data)
features
subject_activity <- final_data[,1:2]
subject_activity
names(subject_activity)
source('~/datasciencecoursera/run_analysis.R')
source('~/datasciencecoursera/run_analysis.R')
names(final_data)
names(activity_labels)
subject_activity <- final_data[,1:2]
names(subject_activity)
final_data <- cbind(subject_activity,mean_std_data)
names(final_data)
final_data <- merge(final_data,activity_labels,by='activity_id',all.x=TRUE)
source('~/datasciencecoursera/run_analysis.R')
final_data$activity_id <- factor(final_data$activity_id, levels = activity_labels[,1], labels = activity_labels[,2])
final_data$subject_id <- as.factor(final_data$subject_id)
final_data.melted <- melt(final_data, id = c("subject", "activity"))
final_data.melted <- melt(final_data, id = c("subject_id", "activity_id"))
final_data.mean <- dcast(final_data.melted, subject + activity ~ variable, mean)
final_data.mean <- dcast(final_data.melted, subject_id + activity_id ~ variable, mean)
source('~/datasciencecoursera/run_analysis.R')
finalDataNoLabel <- final_data[,names(final_data) != 'activity_labels']
tidy_data <- aggregate(finalDataNoLabel[,names(finalDataNoLabel) != c('activity_id','subject_id')],by=list(activity_id=finalDataNoLabel$activity_id,subject_id = finalDataNoLabel$subject_id),mean)
head(tidy_data)
tidyData <- merge(tidyData,activityType,by='activityId',all.x=TRUE)
tidy_data <- merge(tidy_data,activity_labels,by='activity_id',all.x=TRUE)
head(tidy_data)
source('~/datasciencecoursera/run_analysis.R')
activity_labels
